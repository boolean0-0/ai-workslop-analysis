{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f167fc2",
   "metadata": {},
   "source": [
    "# 00 â€” Config & Targets\n",
    "Single source of truth for feeds, timeframe, symbols/phrases, and row caps.\n",
    "This writes `data/raw/config.json` that downstream notebooks will read.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84c5b67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json, datetime as dt\n",
    "\n",
    "# project paths\n",
    "PROJ = Path.cwd().parent if Path.cwd().name == \"notebooks\" else Path.cwd()\n",
    "DATA = PROJ / \"data\"\n",
    "RAW  = DATA / \"raw\"\n",
    "PROC = DATA / \"processed\"\n",
    "OUT  = DATA / \"outputs\"\n",
    "for p in (DATA, RAW, PROC, OUT): p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "CONFIG_PATH = RAW / \"config.json\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32834130",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- EDIT THESE ----\n",
    "\n",
    "# Pick ~10 publications. Swap these for the ones you actually want.\n",
    "# All are RSS URLs; archive URLs also work but RSS is faster/cleaner.\n",
    "SUBSTACKS = {\n",
    "    \"Read Max\": \"https://maxread.substack.com/feed\",\n",
    "    \"Noahpinion\": \"https://noahpinion.substack.com/feed\",\n",
    "    \"The Intrinsic Perspective\": \"https://erikhoel.substack.com/feed\",\n",
    "    \"Cliodynamica by Peter Turchin\": \"https://peterturchin.substack.com/feed\",\n",
    "    \"The Culturist\": \"https://culturist.substack.com/feed\",\n",
    "    \"Story Club by George Saunders\": \"https://georgesaunders.substack.com/feed\",\n",
    "    \"Poetic Outlaws\": \"https://poeticoutlaws.substack.com/feed\",\n",
    "    \"Hardware FYI\": \"https://hardwarefyi.substack.com/feed\",\n",
    "    \"Letters from an American by Heather Cox Richardson\": \"https://heathercoxrichardson.substack.com/feed\",\n",
    "    \"Anton Howes\": \"https://antonhowes.substack.com/feed\",\n",
    "}\n",
    "\n",
    "# TIP: replace with the exact 10 you want. RSS is usually discoverable by appending /feed.\n",
    "\n",
    "# Timeframe â€” keep it generous but finite\n",
    "YEARS_BACK = 2\n",
    "SINCE = (dt.datetime.now(dt.timezone.utc) - dt.timedelta(days=365 * YEARS_BACK)).isoformat()\n",
    "\n",
    "# Cap per publication to keep total rows reasonable for a 1â€“2h project\n",
    "TARGET_POSTS_PER_PUB = 50\n",
    "\n",
    "# Symbols to count later (02 notebook). You can tweak here so it's all centralized.\n",
    "SYMBOLS = {\n",
    "    \"emdash\": \"â€”\",\n",
    "    \"rocket\": \"ðŸš€\",\n",
    "    \"green_check\": \"âœ…\",\n",
    "    \"sparkles\": \"âœ¨\",\n",
    "    \"fire\": \"ðŸ”¥\",\n",
    "    \"robot\": \"ðŸ¤–\",\n",
    "    \"chart_up\": \"ðŸ“ˆ\",\n",
    "    \"ellipsis\": \"â€¦\",\n",
    "}\n",
    "\n",
    "# Common AI-ish phrases to flag\n",
    "PHRASES = [\n",
    "    r\"\\bwe'?re\\s+excited\\s+to\\s+announce\\b\",\n",
    "]\n",
    "\n",
    "# Polite scrape throttle (seconds) used downstream\n",
    "REQUEST_SLEEP_S = 0.2\n",
    "REQUEST_TIMEOUT_S = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bac413a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote data\\raw\\config.json\n"
     ]
    }
   ],
   "source": [
    "cfg = {\n",
    "    \"subscribes\": SUBSTACKS,                     # {name: rss_url}\n",
    "    \"since_iso\": SINCE,                          # ISO8601 string\n",
    "    \"years_back\": YEARS_BACK,\n",
    "    \"target_posts_per_pub\": TARGET_POSTS_PER_PUB,\n",
    "    \"symbols\": SYMBOLS,                          # {label: literal}\n",
    "    \"phrases\": PHRASES,                          # list[regex]\n",
    "    \"request_sleep_s\": REQUEST_SLEEP_S,\n",
    "    \"request_timeout_s\": REQUEST_TIMEOUT_S,\n",
    "}\n",
    "\n",
    "with open(CONFIG_PATH, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(cfg, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"Wrote {CONFIG_PATH.relative_to(PROJ)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22fe1fff",
   "metadata": {},
   "source": [
    "I use Comet to find all of the RSS URLs, so I want to validate the URLs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7349ed4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, feedparser, re\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "PROJ = Path.cwd().parent if Path.cwd().name == \"notebooks\" else Path.cwd()\n",
    "DATA = PROJ / \"data\"; RAW = DATA / \"raw\"; OUT = DATA / \"outputs\"\n",
    "for p in (DATA, RAW, OUT): p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "HEADERS = {\"User-Agent\": \"Mozilla/5.0 (Lincoln/Workslop-FeedCheck)\"}\n",
    "TIMEOUT = 8\n",
    "\n",
    "RSS_CT_HINTS = (\n",
    "    \"application/rss+xml\",\n",
    "    \"application/atom+xml\",\n",
    "    \"application/xml\",\n",
    "    \"text/xml\",\n",
    ")\n",
    "\n",
    "def is_xmlish_content_type(ct: str | None) -> bool:\n",
    "    if not ct: return False\n",
    "    ct = ct.lower()\n",
    "    return any(h in ct for h in RSS_CT_HINTS)\n",
    "\n",
    "def discover_rss_links(page_url: str) -> list[str]:\n",
    "    \"\"\"If page_url is an HTML page, look for <link rel=\"alternate\" type=...> feed links.\"\"\"\n",
    "    try:\n",
    "        r = requests.get(page_url, headers=HEADERS, timeout=TIMEOUT)\n",
    "        r.raise_for_status()\n",
    "    except Exception:\n",
    "        return []\n",
    "    soup = BeautifulSoup(r.text, \"lxml\")\n",
    "    links = []\n",
    "    for tag in soup.find_all(\"link\", attrs={\"rel\": re.compile(r\"\\balternate\\b\", re.I)}):\n",
    "        t = (tag.get(\"type\") or \"\").lower()\n",
    "        if any(h in t for h in RSS_CT_HINTS):\n",
    "            href = tag.get(\"href\")\n",
    "            if href:\n",
    "                links.append(urljoin(page_url, href))\n",
    "    return list(dict.fromkeys(links))  # dedupe preserve order\n",
    "\n",
    "def validate_feed_url(url: str) -> dict:\n",
    "    \"\"\"Return dict with validation details for this URL (RSS/Atom check).\"\"\"\n",
    "    # 1) HEAD check\n",
    "    head_ct = None\n",
    "    try:\n",
    "        h = requests.head(url, headers=HEADERS, allow_redirects=True, timeout=TIMEOUT)\n",
    "        head_ct = h.headers.get(\"Content-Type\", \"\")\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # 2) If HEAD looks non-XML, weâ€™ll still try GET+parse (some servers misreport)\n",
    "    get_ct = None\n",
    "    text_sample = None\n",
    "    try:\n",
    "        g = requests.get(url, headers=HEADERS, allow_redirects=True, timeout=TIMEOUT)\n",
    "        g.raise_for_status()\n",
    "        get_ct = g.headers.get(\"Content-Type\", \"\")\n",
    "        text_sample = g.text[:2000]  # for debugging\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"url\": url,\n",
    "            \"ok\": False,\n",
    "            \"reason\": f\"GET failed: {e.__class__.__name__}\",\n",
    "            \"head_content_type\": head_ct,\n",
    "            \"get_content_type\": get_ct,\n",
    "            \"feed_type\": None,\n",
    "            \"entries\": 0,\n",
    "            \"bozo\": None,\n",
    "        }\n",
    "\n",
    "    # 3) Parse with feedparser\n",
    "    fp = feedparser.parse(text_sample if text_sample else url)\n",
    "    feed_type = None\n",
    "    if fp.version:\n",
    "        # feedparser sets version to e.g. 'rss20', 'atom10'\n",
    "        feed_type = fp.version\n",
    "\n",
    "    entries = len(fp.entries or [])\n",
    "    bozo = getattr(fp, \"bozo\", 0)\n",
    "    ok = bool(feed_type) and entries > 0\n",
    "\n",
    "    # If not ok and content-type is HTML, try discovery\n",
    "    reason = \"\"\n",
    "    if not ok and get_ct and \"html\" in get_ct.lower():\n",
    "        alt_links = discover_rss_links(url)\n",
    "        if alt_links:\n",
    "            # try first discovered link\n",
    "            fp2 = feedparser.parse(alt_links[0])\n",
    "            entries2 = len(fp2.entries or [])\n",
    "            feed_type2 = fp2.version\n",
    "            bozo2 = getattr(fp2, \"bozo\", 0)\n",
    "            if feed_type2 and entries2 > 0 and bozo2 == 0:\n",
    "                return {\n",
    "                    \"url\": url,\n",
    "                    \"ok\": True,\n",
    "                    \"reason\": f\"Discovered RSS via <link>: {alt_links[0]}\",\n",
    "                    \"head_content_type\": head_ct,\n",
    "                    \"get_content_type\": get_ct,\n",
    "                    \"feed_type\": feed_type2,\n",
    "                    \"entries\": entries2,\n",
    "                    \"bozo\": bozo2,\n",
    "                    \"resolved_feed\": alt_links[0],\n",
    "                }\n",
    "            reason = f\"HTML page; discovered feed(s) but parse failed or empty: {alt_links}\"\n",
    "        else:\n",
    "            reason = \"HTML page; no alternate RSS/Atom links found\"\n",
    "    elif not ok:\n",
    "        reason = f\"Parsed but invalid/empty (type={feed_type}, entries={entries}, bozo={bozo})\"\n",
    "\n",
    "    return {\n",
    "        \"url\": url,\n",
    "        \"ok\": ok,\n",
    "        \"reason\": reason,\n",
    "        \"head_content_type\": head_ct,\n",
    "        \"get_content_type\": get_ct,\n",
    "        \"feed_type\": feed_type,\n",
    "        \"entries\": entries,\n",
    "        \"bozo\": bozo,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5836a4f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pub</th>\n",
       "      <th>url</th>\n",
       "      <th>ok</th>\n",
       "      <th>feed_type</th>\n",
       "      <th>entries</th>\n",
       "      <th>head_content_type</th>\n",
       "      <th>get_content_type</th>\n",
       "      <th>bozo</th>\n",
       "      <th>reason</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Anton Howes</td>\n",
       "      <td>https://antonhowes.substack.com/feed</td>\n",
       "      <td>True</td>\n",
       "      <td>rss20</td>\n",
       "      <td>1</td>\n",
       "      <td>application/xml; charset=utf-8</td>\n",
       "      <td>application/xml; charset=utf-8</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cliodynamica by Peter Turchin</td>\n",
       "      <td>https://peterturchin.substack.com/feed</td>\n",
       "      <td>True</td>\n",
       "      <td>rss20</td>\n",
       "      <td>1</td>\n",
       "      <td>application/xml; charset=utf-8</td>\n",
       "      <td>application/xml; charset=utf-8</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hardware FYI</td>\n",
       "      <td>https://hardwarefyi.substack.com/feed</td>\n",
       "      <td>True</td>\n",
       "      <td>rss20</td>\n",
       "      <td>1</td>\n",
       "      <td>application/xml; charset=utf-8</td>\n",
       "      <td>application/xml; charset=utf-8</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Letters from an American by Heather Cox Richar...</td>\n",
       "      <td>https://heathercoxrichardson.substack.com/feed</td>\n",
       "      <td>True</td>\n",
       "      <td>rss20</td>\n",
       "      <td>1</td>\n",
       "      <td>application/xml; charset=utf-8</td>\n",
       "      <td>application/xml; charset=utf-8</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Noahpinion</td>\n",
       "      <td>https://noahpinion.substack.com/feed</td>\n",
       "      <td>True</td>\n",
       "      <td>rss20</td>\n",
       "      <td>1</td>\n",
       "      <td>application/xml; charset=utf-8</td>\n",
       "      <td>application/xml; charset=utf-8</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Poetic Outlaws</td>\n",
       "      <td>https://poeticoutlaws.substack.com/feed</td>\n",
       "      <td>True</td>\n",
       "      <td>rss20</td>\n",
       "      <td>1</td>\n",
       "      <td>application/xml; charset=utf-8</td>\n",
       "      <td>application/xml; charset=utf-8</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Read Max</td>\n",
       "      <td>https://maxread.substack.com/feed</td>\n",
       "      <td>True</td>\n",
       "      <td>rss20</td>\n",
       "      <td>1</td>\n",
       "      <td>application/xml; charset=utf-8</td>\n",
       "      <td>application/xml; charset=utf-8</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Story Club by George Saunders</td>\n",
       "      <td>https://georgesaunders.substack.com/feed</td>\n",
       "      <td>True</td>\n",
       "      <td>rss20</td>\n",
       "      <td>1</td>\n",
       "      <td>application/xml; charset=utf-8</td>\n",
       "      <td>application/xml; charset=utf-8</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>The Culturist</td>\n",
       "      <td>https://culturist.substack.com/feed</td>\n",
       "      <td>True</td>\n",
       "      <td>rss20</td>\n",
       "      <td>1</td>\n",
       "      <td>application/xml; charset=utf-8</td>\n",
       "      <td>application/xml; charset=utf-8</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>The Intrinsic Perspective</td>\n",
       "      <td>https://erikhoel.substack.com/feed</td>\n",
       "      <td>True</td>\n",
       "      <td>rss20</td>\n",
       "      <td>1</td>\n",
       "      <td>application/xml; charset=utf-8</td>\n",
       "      <td>application/xml; charset=utf-8</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 pub  \\\n",
       "0                                        Anton Howes   \n",
       "1                      Cliodynamica by Peter Turchin   \n",
       "2                                       Hardware FYI   \n",
       "3  Letters from an American by Heather Cox Richar...   \n",
       "4                                         Noahpinion   \n",
       "5                                     Poetic Outlaws   \n",
       "6                                           Read Max   \n",
       "7                      Story Club by George Saunders   \n",
       "8                                      The Culturist   \n",
       "9                          The Intrinsic Perspective   \n",
       "\n",
       "                                              url    ok feed_type  entries  \\\n",
       "0            https://antonhowes.substack.com/feed  True     rss20        1   \n",
       "1          https://peterturchin.substack.com/feed  True     rss20        1   \n",
       "2           https://hardwarefyi.substack.com/feed  True     rss20        1   \n",
       "3  https://heathercoxrichardson.substack.com/feed  True     rss20        1   \n",
       "4            https://noahpinion.substack.com/feed  True     rss20        1   \n",
       "5         https://poeticoutlaws.substack.com/feed  True     rss20        1   \n",
       "6               https://maxread.substack.com/feed  True     rss20        1   \n",
       "7        https://georgesaunders.substack.com/feed  True     rss20        1   \n",
       "8             https://culturist.substack.com/feed  True     rss20        1   \n",
       "9              https://erikhoel.substack.com/feed  True     rss20        1   \n",
       "\n",
       "                head_content_type                get_content_type  bozo reason  \n",
       "0  application/xml; charset=utf-8  application/xml; charset=utf-8     1         \n",
       "1  application/xml; charset=utf-8  application/xml; charset=utf-8     1         \n",
       "2  application/xml; charset=utf-8  application/xml; charset=utf-8     1         \n",
       "3  application/xml; charset=utf-8  application/xml; charset=utf-8     1         \n",
       "4  application/xml; charset=utf-8  application/xml; charset=utf-8     1         \n",
       "5  application/xml; charset=utf-8  application/xml; charset=utf-8     1         \n",
       "6  application/xml; charset=utf-8  application/xml; charset=utf-8     1         \n",
       "7  application/xml; charset=utf-8  application/xml; charset=utf-8     1         \n",
       "8  application/xml; charset=utf-8  application/xml; charset=utf-8     1         \n",
       "9  application/xml; charset=utf-8  application/xml; charset=utf-8     1         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote data\\outputs\\rss_validation_report.csv\n"
     ]
    }
   ],
   "source": [
    "import json, pandas as pd\n",
    "CONFIG_PATH = RAW / \"config.json\"\n",
    "cfg = json.load(open(CONFIG_PATH, \"r\", encoding=\"utf-8\"))\n",
    "SUBS = cfg[\"subscribes\"]\n",
    "\n",
    "rows = []\n",
    "for name, url in SUBS.items():\n",
    "    res = validate_feed_url(url)\n",
    "    res[\"pub\"] = name\n",
    "    rows.append(res)\n",
    "\n",
    "df_check = pd.DataFrame(rows)[[\n",
    "    \"pub\", \"url\", \"ok\", \"feed_type\", \"entries\",\n",
    "    \"head_content_type\", \"get_content_type\", \"bozo\", \"reason\"\n",
    "]]\n",
    "df_check = df_check.sort_values([\"ok\",\"pub\"], ascending=[False,True]).reset_index(drop=True)\n",
    "display(df_check)\n",
    "\n",
    "out_csv = OUT / \"rss_validation_report.csv\"\n",
    "df_check.to_csv(out_csv, index=False)\n",
    "print(f\"Wrote {out_csv.relative_to(PROJ)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
